{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lmay1231/cosc470s24/blob/main/Solutions/RegularizationNormalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnIsH_Go2GIx",
        "outputId": "c1c7fb05-5913-4496-85b1-a08f496e7f54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'nn'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 80 (delta 11), reused 5 (delta 1), pack-reused 55\u001b[K\n",
            "Receiving objects: 100% (80/80), 16.44 MiB | 21.98 MiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n",
            "/content/nn\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/kartoone/DeepLearningPython nn\n",
        "%cd nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ***Part 1-Introduce Regularization\n",
        "from network2 import Network, CrossEntropyCost\n",
        "import mnist_loader\n",
        "import numpy as np\n",
        "training_data, validation_data, test_data = mnist_loader.load_data_wrapper ()\n",
        "training_data = list(training_data)\n",
        "test_data = list(test_data) [0:3]\n",
        "\n",
        "# Without Any Regularization\n",
        "net = Network([784, 30, 10], cost=CrossEntropyCost)\n",
        "net.large_weight_initializer()\n",
        "weights = net.SGD(training_data, 30, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True)\n",
        "\n",
        "# With Regularization\n",
        "net2 = Network([784, 30, 10], cost=CrossEntropyCost)\n",
        "net2.large_weight_initializer()\n",
        "weights2 = net2.SGD(training_data, 30, 10, 0.5, lmbda=0.1, evaluation_data=test_data, monitor_evaluation_accuracy=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA1X6HP52QDB",
        "outputId": "cd75e208-80c4-44b1-ecca-f64041ae63bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 training complete\n",
            "Appending weights for epoch 0\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 1 training complete\n",
            "Appending weights for epoch 1\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 2 training complete\n",
            "Appending weights for epoch 2\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 3 training complete\n",
            "Appending weights for epoch 3\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 4 training complete\n",
            "Appending weights for epoch 4\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 5 training complete\n",
            "Appending weights for epoch 5\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 6 training complete\n",
            "Appending weights for epoch 6\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 7 training complete\n",
            "Appending weights for epoch 7\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 8 training complete\n",
            "Appending weights for epoch 8\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 9 training complete\n",
            "Appending weights for epoch 9\n",
            "Accuracy on evaluation data: 3 / 3\n",
            "Epoch 10 training complete\n",
            "Appending weights for epoch 10\n",
            "Accuracy on evaluation data: 3 / 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the magnitude of the sum of weights after each epoch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def getweightsum(epoch_weights):\n",
        "  total_weights = []\n",
        "  # Gets the weights for each epoch for first network\n",
        "  for epoch_weight in epoch_weights:\n",
        "    # Add the manitude of each weight for first layer\n",
        "    l1mag = 0\n",
        "    for l1 in epoch_weight[0]:\n",
        "      for l1weight in l1:\n",
        "        l1mag += abs(l1weight)\n",
        "\n",
        "    # Add the manitude of each weight for second layer\n",
        "    l2mag = 0\n",
        "    for l2 in epoch_weight[1]:\n",
        "      for l2weight in l2:\n",
        "        l2mag += abs(l2weight)\n",
        "\n",
        "    total_weights.append(l1mag + l2mag)\n",
        "\n",
        "  return total_weights\n",
        "\n",
        "epoch_weights = weights[4]\n",
        "epoch_weights2 = weights2[4]\n",
        "no_reg_weights = getweightsum(epoch_weights)\n",
        "reg_weights = getweightsum(epoch_weights2)\n",
        "\n",
        "\n",
        "plt.plot(no_reg_weights, label=\"No Regularization\")\n",
        "plt.plot(reg_weights, label=\"Regularization\")\n",
        "plt.title('Magnitude of Weights with and without Regularization')\n",
        "plt.ylabel('Sum of Weights')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zmOgdbMx2snc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 - Normalization and Handwritten Digit\n",
        "from PIL import Image\n",
        "\n",
        "# Function to test how many images of a category the network gets correct\n",
        "def testing(fileprefix):\n",
        "  base_path = 'new_images/'\n",
        "  accuracy = [0] * 10\n",
        "  print(f'Testing {fileprefix} images:')\n",
        "  correct_str = 'Numbers correctly identified: '\n",
        "  incorrect_str = 'Numbers incorrectly identified: '\n",
        "  for i in range(10):\n",
        "    image_path = base_path + fileprefix + str(i) + '.png'\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Convert the image to array\n",
        "    image_array = np.array(image)/255.0\n",
        "\n",
        "    # Test image\n",
        "    result = np.argmax(net2.feedforward(np.reshape(image_array, (784,1))))\n",
        "    if result == i:\n",
        "      accuracy[i] = 1\n",
        "      correct_str += str(i) + ' '\n",
        "    else:\n",
        "      incorrect_str += str(i) + ' '\n",
        "  print(correct_str)\n",
        "  print(incorrect_str)\n",
        "  print()\n",
        "  return accuracy\n",
        "\n",
        "# Test how many the network gets correct\n",
        "# Accuracy will be stored in 3 arrays\n",
        "good_accuracy = testing('good')\n",
        "large_accuracy = testing('large')\n",
        "small_accuracy = testing('small')\n",
        "\n",
        "# Chart the accuracy for each\n",
        "x = np.array(['Good','Large','Small'])\n",
        "y = np.array([sum(good_accuracy), sum(large_accuracy), sum(small_accuracy)])\n",
        "plt.bar(x,y)\n",
        "plt.title('Accuracy for Handwritten Digits')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number correct')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yOXOzSmmmdmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ***Part 3 - Increased number of training images\n",
        "# Expand the number of images\n",
        "import expand_mnist\n",
        "import mnist_loader\n",
        "import numpy as np\n",
        "training_data, validation_data, test_data = mnist_loader.load_data_wrapper(\"mnist_expanded.pkl.gz\")\n",
        "training_data=list(training_data)\n",
        "test_data = list(test_data)\n",
        "print(len(training_data))"
      ],
      "metadata": {
        "id": "k4HTuFFsx_Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the network\n",
        "net = Network([784, 30, 10], cost=CrossEntropyCost)\n",
        "net.large_weight_initializer()\n",
        "weights = net.SGD(training_data, 30, 10, 0.5, lmbda=0.1, evaluation_data=test_data, monitor_evaluation_accuracy=True)"
      ],
      "metadata": {
        "id": "4e0Cc3DTy8rK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to test how many images of a category the network gets correct\n",
        "def testing(fileprefix):\n",
        "  base_path = 'new_images/'\n",
        "  accuracy = [0] * 10\n",
        "  print(f'Testing {fileprefix} images:')\n",
        "  correct_str = 'Numbers correctly identified: '\n",
        "  incorrect_str = 'Numbers incorrectly identified: '\n",
        "  for i in range(10):\n",
        "    image_path = base_path + fileprefix + str(i) + '.png'\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Convert the image to a array\n",
        "    image_array = np.array(image)/255.0\n",
        "\n",
        "    # Test image\n",
        "    result = np.argmax(net.feedforward(np.reshape(image_array, (784,1))))\n",
        "    if result == i:\n",
        "      accuracy[i] = 1\n",
        "      correct_str += str(i) + ' '\n",
        "    else:\n",
        "      incorrect_str += str(i) + ' '\n",
        "  print(correct_str)\n",
        "  print(incorrect_str)\n",
        "  print()\n",
        "  return accuracy\n",
        "\n",
        "# Test how amount (value) network gets correct\n",
        "# Accuracy will be stored in 3 arrays\n",
        "good_accuracy = testing('good')\n",
        "large_accuracy = testing('large')\n",
        "small_accuracy = testing('small')\n",
        "\n",
        "# Chart the accuracy for each array\n",
        "x = np.array(['Good','Large','Small'])\n",
        "y = np.array([sum(good_accuracy), sum(large_accuracy), sum(small_accuracy)])\n",
        "plt.bar(x,y)\n",
        "plt.title('Accuracy for Handwritten Digits')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Number correct')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZYt0Fq4lzEUp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}